{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make synthetic data\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from snorkel.model.utils import MetalDataset\n",
    "\n",
    "n = 1200\n",
    "X = torch.FloatTensor(np.random.random((n, 2)) * 2 - 1)\n",
    "Y = torch.LongTensor((X[:, 0] > X[:, 1] + 0.5).long() + 1)\n",
    "\n",
    "datasets = []\n",
    "datasets.append(MetalDataset(X[:1000], Y[:1000]))\n",
    "datasets.append(MetalDataset(X[1000:1100], Y[1000:1100]))\n",
    "datasets.append(MetalDataset(X[1100:], Y[1100:]))\n",
    "\n",
    "dataloaders = []\n",
    "for dataset, split in zip(datasets, [\"train\", \"valid\", \"test\"]):\n",
    "    dataloader = DataLoader(dataset, batch_size=4)\n",
    "    dataloader.split = split\n",
    "    dataloaders.append(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add necessary fields to DataLoaders\n",
    "# (do this inside of trainer if passed vanilla DataLoaders)\n",
    "\n",
    "from typing import List\n",
    "from snorkel.mtl.data import MultitaskDataset, MultitaskDataLoader\n",
    "\n",
    "def upgrade_dataloaders(dataloaders: List[DataLoader]):\n",
    "    new_dataloaders = []\n",
    "    for dataloader in dataloaders:\n",
    "        dataset = dataloader.dataset\n",
    "\n",
    "        new_dataset = MultitaskDataset(\n",
    "            name=f\"data_{dataloader.split}\", \n",
    "            X_dict={\"data\": dataset.X},  # This op is specific to TensorDataset\n",
    "            Y_dict={\"labels\": dataset.Y} # Maybe\n",
    "        )\n",
    "        new_dataloader = MultitaskDataLoader(\n",
    "            task_to_label_dict={\"task\": \"labels\"},\n",
    "            dataset=new_dataset,\n",
    "            split=dataloader.split,\n",
    "            batch_size=dataloader.batch_size,\n",
    "            shuffle=(dataloader.split == \"train\")\n",
    "        )\n",
    "        new_dataloaders.append(new_dataloader)\n",
    "    return new_dataloaders\n",
    "\n",
    "dataloaders = upgrade_dataloaders(dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleModel(name=SimpleModel)\n"
     ]
    }
   ],
   "source": [
    "## Build SimpleModel\n",
    "import torch.nn as nn\n",
    "from snorkel.mtl.simple_model import SimpleModel\n",
    "\n",
    "modules = [\n",
    "    nn.Linear(2, 10), \n",
    "    nn.Linear(10, 2),\n",
    "]\n",
    "model = SimpleModel(modules)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task/data_train/train/accuracy': 0.994, 'task/data_valid/valid/accuracy': 0.99, 'task/data_test/test/accuracy': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Train SimpleModel\n",
    "from snorkel.mtl.trainer import Trainer\n",
    "trainer = Trainer(progress_bar=False, n_epochs=5)\n",
    "trainer.train_model(model, dataloaders)\n",
    "scores = model.score(dataloaders)\n",
    "print(scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "eb50e45e-65e0-4135-9b79-2f9d4b028ff1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
