{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import unittest\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from snorkel.mtl.data import MultitaskDataLoader, MultitaskDataset\n",
    "from snorkel.mtl.model import MultitaskModel\n",
    "from snorkel.mtl.modules.utils import ce_loss, softmax\n",
    "from snorkel.mtl.scorer import Scorer\n",
    "from snorkel.mtl.task import Task\n",
    "from snorkel.mtl.trainer import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make data and tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(n):\n",
    "\n",
    "    X = np.random.random((n, 2)) * 2 - 1\n",
    "    Y = np.zeros((n, 2))\n",
    "    Y[:, 0] = (X[:, 0] > X[:, 1] + 0.5).astype(int) + 1\n",
    "    Y[:, 1] = (X[:, 0] > X[:, 1] + 0.25).astype(int) + 1\n",
    "    \n",
    "    df = pd.DataFrame(\n",
    "        {\"x1\": X[:,0],\n",
    "         \"x2\": X[:,1],\n",
    "         \"y1\": Y[:,0],\n",
    "         \"y2\": Y[:,1],\n",
    "        }\n",
    "    )\n",
    "    return df\n",
    "\n",
    "df_train = create_data(1000)\n",
    "df_valid = create_data(100)\n",
    "df_test = create_data(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(df, split):\n",
    "    Y_dict = {}\n",
    "    task_to_label_dict = {}\n",
    "    dataloaders = []\n",
    "    \n",
    "    Y_dict[f\"task1_labels\"] = torch.LongTensor(df[\"y1\"])\n",
    "    task_to_label_dict[\"task1\"] = \"task1_labels\"\n",
    "    \n",
    "    Y_dict[f\"task2_labels\"] = torch.LongTensor(df[\"y2\"])\n",
    "    task_to_label_dict[\"task2\"] = \"task2_labels\"\n",
    "\n",
    "    dataset = MultitaskDataset(\n",
    "        name=\"TestData\", \n",
    "        X_dict={\"coordinates\": \n",
    "                torch.stack((torch.Tensor(df[\"x1\"]), torch.Tensor(df[\"x2\"])), dim=1)}, \n",
    "        Y_dict=Y_dict\n",
    "    )\n",
    "\n",
    "    dataloader = MultitaskDataLoader(\n",
    "        task_to_label_dict=task_to_label_dict,\n",
    "        dataset=dataset,\n",
    "        split=split,\n",
    "        batch_size=4,\n",
    "        shuffle=(split == \"train\"),\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_task(task_name, module_suffixes):\n",
    "    module_pool = nn.ModuleDict(\n",
    "        {\n",
    "            f\"linear1{module_suffixes[0]}\": nn.Linear(2, 10),\n",
    "            f\"linear2{module_suffixes[1]}\": nn.Linear(10, 2),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    task_flow = [\n",
    "        {\n",
    "            \"name\": \"first_layer\",\n",
    "            \"module\": f\"linear1{module_suffixes[0]}\",\n",
    "            \"inputs\": [(\"_input_\", \"coordinates\")],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"second_layer\",\n",
    "            \"module\": f\"linear2{module_suffixes[1]}\",\n",
    "            \"inputs\": [(\"first_layer\", 0)],\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    task = Task(\n",
    "        name=task_name,\n",
    "        module_pool=module_pool,\n",
    "        task_flow=task_flow,\n",
    "        loss_func=partial(ce_loss, \"second_layer\"),\n",
    "        output_func=partial(softmax, \"second_layer\"),\n",
    "        scorer=Scorer(metrics=[\"accuracy\"]),\n",
    "    )\n",
    "\n",
    "    return task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm it builds and trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task1/TestData/train/accuracy': 0.408, 'task2/TestData/train/accuracy': 0.434, 'task1/TestData/valid/accuracy': 0.46, 'task2/TestData/valid/accuracy': 0.52, 'task1/TestData/test/accuracy': 0.35, 'task2/TestData/test/accuracy': 0.42}\n"
     ]
    }
   ],
   "source": [
    "dataloaders = []\n",
    "for df, split in [(df_train, \"train\"), (df_valid, \"valid\"), (df_test, \"test\")]:\n",
    "    dataloader = create_dataloader(df, split)\n",
    "    dataloaders.append(dataloader)\n",
    "task1 = create_task(\"task1\", module_suffixes=[\"A\", \"A\"])\n",
    "task2 = create_task(\"task2\", module_suffixes=[\"A\", \"B\"])\n",
    "model = MultitaskModel(tasks=[task1, task2])\n",
    "scores = model.score(dataloaders)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task1/TestData/train/accuracy': 0.971, 'task2/TestData/train/accuracy': 0.935, 'task1/TestData/valid/accuracy': 0.97, 'task2/TestData/valid/accuracy': 0.93, 'task1/TestData/test/accuracy': 0.97, 'task2/TestData/test/accuracy': 0.96}\n"
     ]
    }
   ],
   "source": [
    "trainer_config = {\"n_epochs\": 2, \"progress_bar\": False}\n",
    "logger_config = {\"counter_unit\": \"epochs\", \"evaluation_freq\": 0.25}\n",
    "\n",
    "trainer = Trainer(**trainer_config, **logger_config)\n",
    "trainer.train_model(model, dataloaders)\n",
    "scores = model.score(dataloaders)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add slicing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.types import DataPoint\n",
    "from snorkel.labeling.apply import LFApplier, PandasLFApplier\n",
    "from snorkel.labeling.lf import labeling_function\n",
    "\n",
    "@labeling_function()\n",
    "def lt42(x: DataPoint) -> int:\n",
    "    return 1 if x.x1 > 0.75 else 0\n",
    "\n",
    "slicing_functions = [lt42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 36583.23it/s]\n"
     ]
    }
   ],
   "source": [
    "applier = PandasLFApplier([lt42])\n",
    "slice_labels = applier.apply(df_train)\n",
    "slice_names = [sf.name for sf in slicing_functions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from snorkel.mtl.task import Task\n",
    "from snorkel.mtl.data import MultitaskDataLoader\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def _update_dataloaders(base_task, dataloaders, slice_labels, slice_names):\n",
    "    # Update dataloaders\n",
    "    for dataloader in dataloaders:\n",
    "        label_name = dataloader.task_to_label_dict[base_task.name]\n",
    "        labels = dataloader.dataset.Y_dict[label_name]\n",
    "        for i, slice_name in enumerate(slice_names):\n",
    "            # Convert labels\n",
    "            ind_labels = torch.LongTensor(slice_labels[:,i]) # [n, 1]\n",
    "            pred_labels = ind_labels * labels\n",
    "\n",
    "            ind_task_name = f\"{base_task.name}_{slice_name}_ind\"\n",
    "            pred_task_name = f\"{base_task.name}_{slice_name}_pred\"\n",
    "            \n",
    "            # Update dataloaders\n",
    "            dataloader.dataset.Y_dict[ind_task_name] = ind_labels\n",
    "            dataloader.dataset.Y_dict[pred_task_name] = pred_labels\n",
    "\n",
    "            dataloader.task_to_label_dict[ind_task_name] = ind_labels\n",
    "            dataloader.task_to_label_dict[pred_task_name] = pred_labels\n",
    "    return dataloaders\n",
    "    \n",
    "    \n",
    "def add_slices(\n",
    "    base_task: Task, \n",
    "    dataloaders: List[MultitaskDataLoader], \n",
    "    slice_labels: csr_matrix,  # [n, m]\n",
    "    slice_names: List[str],\n",
    "):\n",
    "    \"\"\"Adds slice labels to dataloaders and creates new slice tasks (including base slice)\"\"\"    \n",
    "    # Add base slice\n",
    "    num_points, num_slices = slice_labels.shape\n",
    "    base_labels = np.ones((num_points, 1), dtype=int)\n",
    "    slice_labels = np.hstack([slice_labels.toarray(), base_labels])\n",
    "    slice_names.append(f\"base\")\n",
    "    \n",
    "    dataloaders = _update_dataloaders(base_task, dataloaders, slice_labels, slice_names)\n",
    "  \n",
    "    # ----- Update tasks -----\n",
    "    tasks = []\n",
    "    \n",
    "    # Identify base task head and shoulder modules\n",
    "    head_module_name = base_task.task_flow[-1][\"name\"]\n",
    "    head_module = base_task.module_pool[head_module_name]\n",
    "    if isinstance(head_module, nn.DataParallel):\n",
    "        head_module = head_module.module\n",
    "    \n",
    "    shoulder_module_name = base_task.task_flow[-2][\"name\"]\n",
    "    shoulder_module = base_task.module_pool[shoulder_module_name]\n",
    "    if isinstance(shoulder_module, nn.DataParallel):\n",
    "        shoulder_module = shoulder_module.module    \n",
    "    \n",
    "    try:\n",
    "        neck_size = head_module.in_features\n",
    "        cardinality = head_module.out_features\n",
    "    except AttributeError:  # Go one layer deeper past nn.DataParallel\n",
    "        neck_size = head_module.in_features\n",
    "        cardinality = head_module.out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tasks = [task1]\n",
    "\n",
    "# NOTE: modify dataloaders in place, but replace base task that goes in\n",
    "task2_tasks, dataloaders = add_slices(task2, dataloaders, slice_labels, slice_names)\n",
    "tasks = [task1] + task2_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders[0].task_to_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snorkel_env",
   "language": "python",
   "name": "snorkel_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
