{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from snorkel import SnorkelSession\n",
    "\n",
    "from utils import mesh_pairs_from_candidate\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "ChemicalDisease = candidate_subclass('ChemicalDisease', ['chemical', 'disease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "\n",
    "train = session.query(CandidateSet).filter(CandidateSet.name == 'CDR Train Candidates').one()\n",
    "dev = session.query(CandidateSet).filter(CandidateSet.name == 'CDR Development Candidates').one()\n",
    "test = session.query(CandidateSet).filter(CandidateSet.name == 'CDR Test Candidates').one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET FEATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import FeatureManager\n",
    "\n",
    "feature_manager = FeatureManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get span features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.features import get_span_feats\n",
    "\n",
    "%time F_train_span = feature_manager.create(session, train, 'training span feats n', get_span_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time F_dev_span = feature_manager.update(session, dev, 'training span feats n', False, get_span_feats)\n",
    "%time F_test_span = feature_manager.update(session, test, 'training span feats n', False, get_span_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time F_train_span = feature_manager.load(session, train, 'training span feats')\n",
    "%time F_dev_span = feature_manager.load(session, dev, 'training span feats')\n",
    "%time F_test_span = feature_manager.load(session, test, 'training span feats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F_train_span"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Get mention split feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cdr_feats import get_span_splits\n",
    "\n",
    "%time F_train_splits = feature_manager.create(session, train, 'training span splits', get_span_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time F_dev_splits = feature_manager.update(session, dev, 'training span splits', False, get_span_splits)\n",
    "%time F_test_splits = feature_manager.update(session, test, 'training span splits', False, get_span_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time F_train_splits = feature_manager.load(session, train, 'training span splits')\n",
    "%time F_dev_splits = feature_manager.load(session, dev, 'training span splits')\n",
    "%time F_test_splits = feature_manager.load(session, test, 'training span splits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get key mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cdr_feats import get_is_key\n",
    "\n",
    "%time F_train_keys = feature_manager.create(session, train, 'training key ents', get_is_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time F_dev_keys = feature_manager.update(session, dev, 'training key ents', False, get_is_key)\n",
    "%time F_test_keys = feature_manager.update(session, test, 'training key ents', False, get_is_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time F_train_keys = feature_manager.load(session, train, 'training key ents')\n",
    "%time F_dev_keys = feature_manager.load(session, dev, 'training key ents')\n",
    "%time F_test_keys = feature_manager.load(session, test, 'training key ents')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get title span feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cdr_feats import get_title_span_feats\n",
    "\n",
    "%time F_train_title_span = feature_manager.create(session, train, 'training title span', get_title_span_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time F_dev_title_span = feature_manager.update(session, dev, 'training title span', False, get_title_span_feats)\n",
    "%time F_test_title_span = feature_manager.update(session, test, 'training title span', False, get_title_span_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time F_train_title_span = feature_manager.load(session, train, 'training title span')\n",
    "%time F_dev_title_span = feature_manager.load(session, dev, 'training title span')\n",
    "%time F_test_title_span = feature_manager.load(session, test, 'training title span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print repr(F_train_span)\n",
    "print repr(F_train_splits)\n",
    "print repr(F_train_keys)\n",
    "print repr(F_train_title_span)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "with open('data/doc_relation_dict.pkl', 'rb') as f:\n",
    "    train_doc_dict, dev_doc_dict, test_doc_dict = cPickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_labels = np.zeros(len(train))\n",
    "\n",
    "for i in xrange(len(train)):\n",
    "    candidate = train[i]\n",
    "    pubmed_id, pairs = mesh_pairs_from_candidate(candidate)\n",
    "    if pubmed_id not in train_doc_dict:\n",
    "        continue\n",
    "    for c, d in pairs:\n",
    "        if (c, d) in train_doc_dict[pubmed_id]:\n",
    "            train_labels[i] = 1\n",
    "            break\n",
    "    else:\n",
    "        train_labels[i] = -1\n",
    "            \n",
    "with open('taggerone-train-labels.pkl', 'wb') as f:\n",
    "    cPickle.dump(train_labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('taggerone-train-labels.pkl', 'rb') as f:\n",
    "    train_labels = cPickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEARN GEN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "\n",
    "with open('data/ctd.pkl', 'rb') as ctd_f:\n",
    "    ctd_unspecified, ctd_therapy, ctd_marker = cPickle.load(ctd_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cand_in_ctd_unspecified(c):\n",
    "    _, pairs = mesh_pairs_from_candidate(c)\n",
    "    return 1 if any([pair in ctd_unspecified for pair in pairs]) else 0\n",
    "\n",
    "def cand_in_ctd_therapy(c):\n",
    "    _, pairs = mesh_pairs_from_candidate(c)\n",
    "    return 1 if any([pair in ctd_therapy for pair in pairs]) else 0\n",
    "\n",
    "def cand_in_ctd_marker(c):\n",
    "    _, pairs = mesh_pairs_from_candidate(c)\n",
    "    return 1 if any([pair in ctd_marker for pair in pairs]) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    gen_LF_text_btw,\n",
    "    gen_LF_span,\n",
    "    gen_LF_regex,\n",
    "    gen_LF_regex_AB,\n",
    "    gen_LF_regex_BA,\n",
    "    gen_LF_regex_A,\n",
    "    gen_LF_regex_B,\n",
    "    ltp,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import random\n",
    "import re\n",
    "from snorkel.lf_helpers import get_tagged_text, get_text_between\n",
    "\n",
    "#####################################################################################\n",
    "##################################### BASIC CTD #####################################\n",
    "#####################################################################################\n",
    "\n",
    "def LF_in_ctd_unspecified(c):\n",
    "    \"\"\"Match against the ctd KB, with random negative supervision as well\"\"\"\n",
    "    return -1 * cand_in_ctd_unspecified(c)\n",
    "\n",
    "def LF_in_ctd_therapy(c):\n",
    "    \"\"\"Match against the ctd KB, with random negative supervision as well\"\"\"\n",
    "    return -1 * cand_in_ctd_therapy(c)\n",
    "\n",
    "def LF_in_ctd_marker(c):\n",
    "    \"\"\"Match against the ctd KB, with random negative supervision as well\"\"\"\n",
    "    return cand_in_ctd_marker(c)\n",
    "\n",
    "#####################################################################################\n",
    "##################################### BASIC BTW #####################################\n",
    "#####################################################################################\n",
    "\n",
    "def LF_induce(c):\n",
    "    return 1 if re.search(r'{{A}}.{0,20}induc.{0,20}{{B}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "causal_past = ['induced', 'caused', 'due']\n",
    "\n",
    "def LF_d_induced_by_c(c):\n",
    "    return gen_LF_regex_BA(c, '.{0,50}' + ltp(causal_past) + '.{0,9}(by|to).{0,50}', 1)\n",
    "def LF_d_induced_by_c_tight(c):\n",
    "    return gen_LF_regex_BA(c, '.{0,50}' + ltp(causal_past) + ' (by|to) ', 1)\n",
    "def LF_d_augmented_by_c_tight(c):\n",
    "    return gen_LF_regex_BA(c, '.{0,250}augmented by ', 1)\n",
    "\n",
    "def LF_induce_name(c):\n",
    "    return 1 if 'induc' in c.chemical.get_span().lower() else 0     \n",
    "\n",
    "causal = ['cause[sd]?', 'induce[sd]?', 'associated with']\n",
    "def LF_c_cause_d(c):\n",
    "    return 1 if (\n",
    "        re.search(r'{{A}}.{0,50} ' + ltp(causal) + '.{0,50}{{B}}', get_tagged_text(c), re.I)\n",
    "        and not re.search('{{A}}.{0,50}(not|no).{0,20}' + ltp(causal) + '.{0,50}{{B}}', get_tagged_text(c), re.I)\n",
    "    ) else 0\n",
    "\n",
    "def LF_observe(c):\n",
    "    return 1 if re.search(r'{{A}}.{0,20}observ.{0,20}{{B}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "treat = ['treat', 'effective', 'prevent', 'resistant', 'slow', 'promise', 'therap']\n",
    "def LF_d_treat_c(c):\n",
    "    return gen_LF_regex_BA(c, '.{0,50}' + ltp(treat) + '.{0,50}', -1)\n",
    "def LF_c_treat_d(c):\n",
    "    return gen_LF_regex_AB(c, '.{0,50}' + ltp(treat) + '.{0,50}', -1)\n",
    "def LF_treat_d(c):\n",
    "    return gen_LF_regex_B(c, ltp(treat) + '.{0,50}', -1)\n",
    "def LF_c_treat_d_wide(c):\n",
    "    return gen_LF_regex_AB(c, '.{0,200}' + ltp(treat) + '.{0,200}', -1)\n",
    "\n",
    "def LF_didnot(c):\n",
    "    return -1 if re.search(r'{{A}}.{0,20}does|did not.{0,20}{{B}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "def LF_close_CD(c):\n",
    "    return 1 if re.search(r'{{A}}.{2,20}{{B}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "def LF_close_DC(c):\n",
    "    return 1 if re.search(r'{{B}}.{2,20}{{A}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "def LF_c_d(c):\n",
    "    return 1 if ('{{A}} {{B}}' in get_tagged_text(c)) else 0\n",
    "\n",
    "\n",
    "def LF_c_induced_d(c):\n",
    "    return 1 if (\n",
    "        ('{{A}} {{B}}' in get_tagged_text(c)) and \n",
    "        (('-induc' in c[0].get_span().lower()) or ('-assoc' in c[0].get_span().lower()))\n",
    "        ) else 0\n",
    "\n",
    "def LF_improve_before_disease(c):\n",
    "    return gen_LF_regex_B(c, 'improv.*', -1)\n",
    "\n",
    "def LF_not_chemical(c):\n",
    "    return gen_LF_regex_A(c, 'not.{0,3}', -1)\n",
    "\n",
    "def LF_c_give_increases_d(c):\n",
    "    return gen_LF_regex_AB(c, '.{0,10}giv.{0,25}increas.{0,25}', 1)\n",
    "def LF_c_increases_d(c):\n",
    "    return gen_LF_regex_AB(c, '.{0,25}increas.{0,25}', 1)\n",
    "\n",
    "def LF_no_effect(c):\n",
    "    return -1 if re.search('no effect on.{0,5}{{B}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "pat_terms = ['in a patient with ', 'in patients with']\n",
    "def LF_in_patient_with(c):\n",
    "    return -1 if re.search(ltp(pat_terms) + '{{B}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "uncertain = ['combin', 'possible', 'unlikely']\n",
    "def LF_uncertain(c):\n",
    "    return gen_LF_regex_A(c, ltp(uncertain) + '.*', -1)\n",
    "\n",
    "def LF_induced_other(c):\n",
    "    return gen_LF_regex(c, '{{A}}.{20,1000}-induced {{B}}', -1)\n",
    "\n",
    "def LF_far_c_d(c):\n",
    "    return gen_LF_regex_AB(c, '.{100,5000}', -1)\n",
    "def LF_far_d_c(c):\n",
    "    return gen_LF_regex_BA(c, '.{100,5000}', -1)\n",
    "\n",
    "def LF_risk_d(c):\n",
    "    return gen_LF_regex_B(c, 'risk of ', 1)\n",
    "\n",
    "other_meaning = ['depression']\n",
    "def LF_d_meaning(c):\n",
    "    return -1 if (c[1].get_span().lower() in other_meaning) and (re.search(r'{{B}} (in|of)', get_tagged_text(c), flags=re.I)) else 0\n",
    "\n",
    "def LF_develop_d_following_c(c):\n",
    "    return 1 if re.search(r'develop.{0,25}{{B}}.{0,25}following.{0,25}{{A}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "procedure = ['inject', 'administrat']\n",
    "occur = ['occur']\n",
    "following = ['following']\n",
    "def LF_c_d_occur(c):\n",
    "    return 1 if re.search(ltp(procedure) + '.{0,50}{{A}}.{0,50}{{B}}.{0,50}' + ltp(occur), get_tagged_text(c), flags=re.I) else 0\n",
    "def LF_d_following_c(c):\n",
    "    return 1 if re.search('{{B}}.{0,50}' + ltp(following) + '.{0,20}{{A}}.{0,50}' + ltp(procedure), get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "def LF_measure(c):\n",
    "    return -1 if re.search('measur.{0,75}{{A}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "def LF_level(c):\n",
    "    return -1 if re.search('{{A}}.{0,25} level', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "def LF_protein(c):\n",
    "    return -1 if re.search('{{A}}.{0,50}protein', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "def LF_gene(c):\n",
    "    return -1 if re.search('{{A}} .{0,50} gene', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "def LF_neg_d(c):\n",
    "    return -1 if re.search('(none|not|no) .{0,25}{{B}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "def LF_preexist(c):\n",
    "    return -1 if 'exist' in get_tagged_text(c) else 0\n",
    "\n",
    "#####################################################################################\n",
    "##################################### DEPEND CTD ####################################\n",
    "#####################################################################################\n",
    "\n",
    "def LF_ctd_marker_c_d(c):\n",
    "    return LF_c_d(c) * cand_in_ctd_marker(c)\n",
    "\n",
    "def LF_ctd_marker_induce(c):\n",
    "    return (LF_c_induced_d(c) or LF_d_induced_by_c_tight(c)) * cand_in_ctd_marker(c)\n",
    "\n",
    "def LF_ctd_therapy_treat(c):\n",
    "    return LF_c_treat_d_wide(c) * cand_in_ctd_therapy(c)\n",
    "\n",
    "def LF_ctd_unspecified_treat(c):\n",
    "    return LF_c_treat_d_wide(c) * cand_in_ctd_unspecified(c)\n",
    "\n",
    "def LF_ctd_unspecified_induce(c):\n",
    "    return (LF_c_induced_d(c) or LF_d_induced_by_c_tight(c)) * cand_in_ctd_unspecified(c)\n",
    "    \n",
    "#####################################################################################\n",
    "###################################### LOGICAL ######################################\n",
    "#####################################################################################\n",
    "\n",
    "WEAK_PHRASES = ['none', 'although', 'was carried out', 'was conducted',\n",
    "                'seems', 'suggests', 'risk', 'implicated',\n",
    "               'the aim', 'to (investigate|assess|study)']\n",
    "\n",
    "WEAK_RGX = r'|'.join(WEAK_PHRASES)\n",
    "\n",
    "def LF_weak_assertions(c):\n",
    "    return -1 if re.search(WEAK_RGX, get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "#####################################################################################\n",
    "###################################### ADVANCED #####################################\n",
    "#####################################################################################\n",
    "\n",
    "def LF_closer_chem(c):\n",
    "    chem_start, chem_end = c.chemical.get_word_start(), c.chemical.get_word_end()\n",
    "    dis_start, dis_end = c.disease.get_word_start(), c.disease.get_word_end()\n",
    "    if dis_start < chem_start:\n",
    "        dist = chem_start - dis_end\n",
    "    else:\n",
    "        dist = dis_start - chem_end\n",
    "    sent = c.chemical.parent\n",
    "    closest_other_chem = float('inf')\n",
    "    for i in range(dis_end, min(len(sent.words), dis_end + dist / 2)):\n",
    "        t = sent.ner_tags[i] \n",
    "        if t.startswith('Chemical') and t != sent.ner_tags[chem_start]:\n",
    "            return -1\n",
    "    for i in range(max(0, dis_start - dist / 2), dis_start):\n",
    "        t = sent.ner_tags[i] \n",
    "        if t.startswith('Chemical') and t != sent.ner_tags[chem_start]:\n",
    "            return -1\n",
    "    return 0\n",
    "\n",
    "def LF_closer_dis(c):\n",
    "    chem_start, chem_end = c.chemical.get_word_start(), c.chemical.get_word_end()\n",
    "    dis_start, dis_end = c.disease.get_word_start(), c.disease.get_word_end()\n",
    "    if dis_start < chem_start:\n",
    "        dist = chem_start - dis_end\n",
    "    else:\n",
    "        dist = dis_start - chem_end\n",
    "    sent = c.chemical.parent\n",
    "    for i in range(chem_end, min(len(sent.words), chem_end + dist / 8)):\n",
    "        t = sent.ner_tags[i] \n",
    "        if t.startswith('Disease') and t != sent.ner_tags[dis_start]:\n",
    "            return -1\n",
    "    for i in range(max(0, chem_start - dist / 8), chem_start):\n",
    "        t = sent.ner_tags[i] \n",
    "        if t.startswith('Disease') and t != sent.ner_tags[dis_start]:\n",
    "            return -1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LFs = [\n",
    "    LF_in_ctd_therapy,\n",
    "    LF_in_ctd_marker,\n",
    "    LF_ctd_marker_c_d,\n",
    "    LF_ctd_marker_induce,\n",
    "    LF_ctd_therapy_treat,\n",
    "    LF_ctd_unspecified_treat,\n",
    "    LF_ctd_unspecified_induce,\n",
    "    LF_induce,\n",
    "    LF_d_induced_by_c,\n",
    "    LF_d_induced_by_c_tight,\n",
    "    LF_d_augmented_by_c_tight,\n",
    "    LF_induce_name,\n",
    "    LF_c_cause_d,\n",
    "    LF_observe,\n",
    "    LF_d_treat_c,\n",
    "    LF_c_treat_d,\n",
    "    LF_treat_d,\n",
    "    LF_c_treat_d_wide,\n",
    "    LF_c_d,\n",
    "    LF_c_induced_d,\n",
    "    LF_improve_before_disease,\n",
    "    LF_not_chemical,\n",
    "    LF_c_increases_d,\n",
    "    LF_no_effect,\n",
    "    LF_in_patient_with,\n",
    "    LF_uncertain,\n",
    "    LF_induced_other,\n",
    "    LF_far_c_d,\n",
    "    LF_far_d_c,\n",
    "    LF_risk_d,\n",
    "    LF_d_meaning,\n",
    "    LF_develop_d_following_c,\n",
    "    LF_d_following_c,\n",
    "    LF_weak_assertions,\n",
    "    LF_measure,\n",
    "    LF_level,\n",
    "    LF_protein,\n",
    "    LF_neg_d,\n",
    "    LF_preexist,\n",
    "    LF_closer_chem,\n",
    "    LF_closer_dis,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelManager\n",
    "\n",
    "label_manager = LabelManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time L_train = label_manager.create(session, train, 'LF Labels', f=LFs)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time L_train = label_manager.load(session, train, 'LF Labels')\n",
    "L_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_train.lf_stats(train_labels).sort('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning.structure import DependencySelector\n",
    "ds = DependencySelector()\n",
    "deps = ds.select(L_train, threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "from snorkel.learning.constants import *\n",
    "\n",
    "gen_model = GenerativeModel(lf_prior=True, lf_propensity=True)\n",
    "gen_model.train(L_train, step_size=0.1/L_train.shape[0], reg_type=2, epochs=15, decay=1.0, reg_param=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(train_marginals, bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cov = np.where(np.abs(train_marginals - 0.5) > 1e-6)[0]\n",
    "print \"Non-0.5 examples: {0} ({1:.2f}%)\".format(len(cov), 100 * float(len(cov)) / len(train_marginals))\n",
    "\n",
    "gen_labels = (train_marginals[cov] > 0.5)\n",
    "cov_gold = (1+train_labels[cov]) / 2\n",
    "print \"Non-0.5 accuracy wrt train labels: {0:.3f}%\".format(100 * np.mean(gen_labels == cov_gold))\n",
    "\n",
    "pos = np.where(cov_gold > 0.5)[0]\n",
    "print \"Positive class accuracy: {0:.3f}%\".format(100 * np.mean(gen_labels[pos] == cov_gold[pos]))\n",
    "neg = np.where(cov_gold < 0.5)[0]\n",
    "print \"Negative class accuracy: {0:.3f}%\".format(100 * np.mean(gen_labels[neg] == cov_gold[neg]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = 0.5\n",
    "\n",
    "fn_idxs = np.where((train_marginals <= b) * (train_labels > b))[0]\n",
    "fp_idxs = np.where((train_marginals > b) * (train_labels <= b))[0]\n",
    "tp_idxs = np.where((train_marginals > b) * (train_labels > b))[0]\n",
    "tn_idxs = np.where((train_marginals <= b) * (train_labels <= b))[0]\n",
    "\n",
    "\n",
    "n_tp, n_fp, n_fn, n_tn = len(tp_idxs), len(fp_idxs), len(fn_idxs), len(tn_idxs)\n",
    "p = float(n_tp) / (n_tp + n_fp) if n_tp > 0 else 0\n",
    "r = float(n_tp) / (n_tp + n_fn) if n_tp > 0 else 0\n",
    "f1 = 2 * p * r / (p + r) if (p + r) > 0 else 0\n",
    "\n",
    "print '#tp = {0}\\n#fp = {1}\\n#fn = {2}\\n#tn = {3}'.format(n_tp, n_fp, n_fn, n_tn)\n",
    "print 'precision = {0:.3f}\\nrecall = {1:.3f}\\nf1 = {2:.3f}'.format(p, r, f1)\n",
    "\n",
    "print(sum([n_tp, n_fp, n_fn, n_tn]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING TRICKS ON TRICKS ON TRICKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning.utils import ListParameter, RangeParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning.fastmulticontext import get_matrix_keys\n",
    "train_embed_xs = get_matrix_keys([F_train_span, F_train_title_span])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from utils import CDRFMCT, CDRRandomSearch\n",
    "\n",
    "epoch_param = RangeParameter('epoch', 20, 200, step=20)\n",
    "lr_param = RangeParameter('lr', 1e-5, 0.1, step=0.5, log_base=10)\n",
    "lambda_param = RangeParameter('lr', 1e-5, 10, step=1, log_base=10)\n",
    "dim_param = RangeParameter('dim', 25, 150, step=25)\n",
    "minct_opts = [1, 2, 3, 5, 7, 10, 12, 15]\n",
    "minct_param = ListParameter('min_ct', minct_opts)\n",
    "\n",
    "disc_model = CDRFMCT()\n",
    "\n",
    "searcher = CDRRandomSearch(disc_model, train_marginals, train_embed_xs, 20,\n",
    "                           epoch_param, lr_param, dim_param, lambda_param, minct_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from snorkel.learning.fastmulticontext import get_matrix_keys\n",
    "dev_embed_xs = get_matrix_keys([F_dev_span, F_dev_title_span])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from snorkel.models import Corpus\n",
    "dev_corpus = session.query(Corpus).filter(Corpus.name == 'CDR Development').one()\n",
    "\n",
    "D = searcher.fit(dev_embed_xs, F_dev_keys.toarray(), dev_doc_dict, dev, dev_corpus, b=0.5,\n",
    "                 raw_xs=F_train_keys.toarray(), n_threads=4, n_print=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "disc_model.train(train_marginals, train_embed_xs, raw_xs=F_train_keys.toarray(),\n",
    "                 epoch=160, dim=100, lr = 0.001, min_ct = [10,5], lambda_l2 = 0.01,\n",
    "                 seed=1701, n_threads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_embed_xs = get_matrix_keys([F_test_span, F_test_title_span])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_corpus = session.query(Corpus).filter(Corpus.name == 'CDR Test').one()\n",
    "buckets = disc_model.score(test_embed_xs, F_test_keys.toarray(), test_doc_dict, test, test_corpus, b=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
