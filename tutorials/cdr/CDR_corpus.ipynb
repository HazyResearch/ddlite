{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chemical-Disease Relation (CDR) Tutorial\n",
    "\n",
    "In this example, we'll be writing an application to extract *mentions of* **chemical-induced-disease relationships** from Pubmed abstracts, as per the [BioCreative CDR Challenge](http://www.biocreative.org/resources/corpora/biocreative-v-cdr-corpus/).  At core, we will be constructing a model to classify _candidate_ CDR mentions as either true or false."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Preprocessing\n",
    "\n",
    "**Before starting, make sure to run the download_data.sh script!**\n",
    "\n",
    "In this notebook, we'll preprocess several documents using `Snorkel` utilities, parsing them into a simple hierarchy of component parts of our input data--which we refer to as _contexts_--as well as extracting standard linguistic features from each context.\n",
    "\n",
    "In this example, we will extract two types of contexts, represented as `Context` subclasses: `Document` and constituent `Sentence` objects.  In particular, we'll do this using [CoreNLP](http://stanfordnlp.github.io/CoreNLP/), which will also extract a number of standard linguistic features which will be used downstream.\n",
    "\n",
    "All of this preprocessed input data will be saved to a database.  In Snorkel, if no database is specified, then a SQLite database is created by default- so no setup is needed here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the `Corpus`\n",
    "\n",
    "First, we will load and pre-process the corpus, storing it for convenience in a `Corpus` object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring a `DocParser`\n",
    "\n",
    "We'll start by defining a `DocParser` class to read in Pubmed abstracts from [Pubtator]([Pubtator](http://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/PubTator/index.cgi)), where they are stored along with \"gold\" (i.e. hand-annotated by experts) *chemical* and *disease mention* annotations. We'll use the `XMLDocParser` class, which allows us to use [XPath queries](https://en.wikipedia.org/wiki/XPath) to specify the relevant sections of the XML format.\n",
    "\n",
    "_Note that we are newline-concatenating text from the title and abstract together for simplicity, but if we wanted to, we could easily extend the `DocParser` classes to preserve information about document structure._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import XMLMultiDocParser\n",
    "\n",
    "xml_parser = XMLMultiDocParser(\n",
    "    path='data/CDR_TrainingSet.BioC.xml',\n",
    "    doc='.//document',\n",
    "    text='.//passage/text/text()',\n",
    "    id='.//id/text()')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a `SentenceParser`\n",
    "\n",
    "Next, we'll use an NLP preprocessing tool to split the `Document` objects into sentences, tokens, and provide annotations--part-of-speech tags, dependency parse structure, lemmatized word forms, etc.--for these sentences.  Here we use the default `SentenceParser` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import CDRSentenceParser\n",
    "\n",
    "cdr_sent_parser = CDRSentenceParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import CorpusParser\n",
    "\n",
    "cp = CorpusParser(xml_parser, cdr_sent_parser, max_docs=500)\n",
    "%time corpus = cp.parse_corpus(name='CDR Train', session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "session.add(corpus)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeating for development and test corpora\n",
    "We will rerun the same operations for the other two CDR corpora: development and test. All we do is change the path that the `XMLMultiDocParser` uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import TaggerOneSentenceParser\n",
    "\n",
    "taggerone_sent_parser = TaggerOneSentenceParser()\n",
    "cp_test = CorpusParser(xml_parser, taggerone_sent_parser, max_docs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cp_test.doc_parser.path = 'data/CDR_DevelopmentSet.BioC.xml'\n",
    "%time corpus = cp.parse_corpus(name='CDR Development', session=session)\n",
    "session.add(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cp_test.doc_parser.path = 'data/CDR_TestSet.BioC.xml'\n",
    "%time corpus = cp_test.parse_corpus(name='CDR Test', session=session)\n",
    "session.add(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: `Candidate` Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "ChemicalDisease = candidate_subclass('ChemicalDisease', ['chemical', 'disease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import Ngrams\n",
    "from snorkel.matchers import RegexMatchEach\n",
    "\n",
    "ngrams = Ngrams(n_max=6)\n",
    "\n",
    "dis_matcher = RegexMatchEach(attrib='entity_types', rgx=r'^Disease', longest_match_only=True)\n",
    "chem_matcher = RegexMatchEach(attrib='entity_types', rgx=r'^Chemical', longest_match_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import CandidateExtractor\n",
    "\n",
    "ce = CandidateExtractor(ChemicalDisease, [ngrams, ngrams], [chem_matcher, dis_matcher])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from snorkel.models import Corpus\n",
    "\n",
    "for corpus_name in ['CDR Train']:#, 'CDR Development', 'CDR Test']:\n",
    "    corpus = session.query(Corpus).filter(Corpus.name == corpus_name).one()\n",
    "    sentences = set()\n",
    "    for document in corpus:\n",
    "        for sentence in document.sentences:\n",
    "            sentences.add(sentence)\n",
    "    \n",
    "    %time c = ce.extract(sentences, corpus_name + ' Candidates', session)\n",
    "    session.add(c)\n",
    "session.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
