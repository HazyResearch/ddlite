{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"imgs/logo.jpg\" width=\"50px\" style=\"margin-right:10px\">\n",
    "\n",
    "# Snorkel Workshop: Extracting Spouse Relations <br> from the News\n",
    "## Part 2: Writing  Labeling Functions\n",
    "\n",
    "__TODO: change explanation to be in terms of spouse pairs and sentence instead of candidates__\n",
    "\n",
    "In Snorkel, our primary interface through which we provide training signal to the end extraction model we are training is by writing **labeling functions (LFs)** (as opposed to hand-labeling massive training sets).  We'll go through some examples for our spouse extraction task below.\n",
    "\n",
    "A labeling function isn't anything special. It's just a Python function that accepts a `Candidate` as the input argument and returns `1` if it says the `Candidate` should be marked as true, `-1` if it says the `Candidate` should be marked as false, and `0` if it doesn't know how to vote and abstains. In practice, many labeling functions are unipolar: it labels only `1`s and `0`s, or it labels only `-1`s and `0`s.\n",
    "\n",
    "Recall that our goal is to ultimately train a high-performance classification model that predicts which of our `Candidate`s are true mentions of spouse relations.  It turns out that we can do this by writing potentially low-quality labeling functions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Background\n",
    "\n",
    "## A. Preprocessing the Database\n",
    "\n",
    "In a real application, there is a lot of data preparation, parsing, and database loading that needs to be completed before we dive into writing labeling functions. Here we've pre-generated a database instance for you. All _candidates_ and _gold labels_ (i.e., human-generated labels) are queried from this database for use in the the tutorial. \n",
    "\n",
    "## B. Using a _Development Set_ of Human-labeled Data\n",
    "\n",
    "In our setting, we will use the phrase _development set_ to refer to a set of examples (here, a subset of our training set) which we label by hand and use to help us develop and refine labeling functions.  Unlike the _test set_, which we do not look at and use for final evaluation, we can inspect the development set while writing labeling functions. This is a list of `{-1,1}` labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: make it the same pickle.\n",
    "dev_data = pd.read_pickle(\"dev_data.pkl\")\n",
    "dev_labels = np.load(\"dev_labels.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Labeling Function Metrics\n",
    "\n",
    "### 1. Coverage\n",
    "One simple metric we can compute quickly is our _coverage_, the number of candidates labeled by our LF, on our training set (or any other set).\n",
    "\n",
    "### 2. Precision / Recall / F1\n",
    "If we have gold labeled data, we can also compute standard precision, recall, and F1 metrics for the output of a single labeling function. These metrics are computed over 4 _error buckets_: _True Positives_ (tp), _False Positives_ (fp), _True Negatives_ (tn), and _False Negatives_ (fn).\n",
    "\n",
    "\\begin{equation*}\n",
    "precision = \\frac{tp}{(tp + fp)}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "recall = \\frac{tp}{(tp + fn)}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "F1 = 2 \\cdot \\frac{ (precision \\cdot recall)}{(precision + recall)}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Labeling Functions\n",
    "\n",
    "## A. Pattern Matching Labeling Functions\n",
    "\n",
    "One powerful form of labeling function design is defining sets of keywords or regular expressions that, as a human labeler, you know are correlated with the true label. In the terminology of [Bayesian inference](https://en.wikipedia.org/wiki/Statistical_inference#Bayesian_inference), this can be thought of as defining a [_prior_](https://en.wikipedia.org/wiki/Prior_probability) over your word features. \n",
    "\n",
    "For example, we could define a dictionary of terms that occur between person names in a candidate. One simple dictionary of terms indicating a true relation could be:\n",
    "    \n",
    "    spouses = {'husband', 'wife'}\n",
    " \n",
    "We can then write a labeling function that checks for a match with these terms in the text that occurs between person names.\n",
    "\n",
    "    @labeling_function(resources=dict(spouses=['husband','wife']))\n",
    "    def LF_husband_wife(x: DataPoint, spouses: List[str]) -> int:\n",
    "        for word in spouses:\n",
    "            return 1 if word in x.text_between.split(' ') else 0\n",
    "        return 0\n",
    "        \n",
    "The idea is that we can easily create dictionaries that encode themes or categories descibing all kinds of relationships between 2 people and then use these objects to _weakly supervise_ our classification task.\n",
    "\n",
    "    other_relationship = {'boyfriend', 'girlfriend'}\n",
    "    \n",
    "**IMPORTANT** Good labeling functions manage a trade-off between high coverage and high precision. When constructing your dictionaries, think about building larger, noiser sets of terms instead of relying on 1 or 2 keywords. Sometimes a single word can be very predictive (e.g., `ex-wife`) but it's almost always better to define something more general, such as a regular expression pattern capturing _any_ string with the `ex-` prefix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: WHY DO I NEED THIS?!\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dictionary update sequence element #0 has length 7; 2 is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-c1484dc71305>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspouses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: dictionary update sequence element #0 has length 7; 2 is required"
     ]
    }
   ],
   "source": [
    "dict(spouses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from snorkel.labeling.apply import PandasLFApplier\n",
    "from snorkel.labeling.lf import labeling_function\n",
    "from snorkel.types import DataPoint\n",
    "\n",
    "spouses = ['spouse', 'wife', 'husband', 'ex-wife', 'ex-husband']\n",
    "@labeling_function(resources=dict(spouses=spouses))\n",
    "def LF_husband_wife(x: DataPoint, spouses: List[str]) -> int:\n",
    "    return 1 if len(set(spouses).intersection(set(x.between_tokens))) > 0 else 0\n",
    "\n",
    "@labeling_function(resources=dict(spouses=spouses))\n",
    "def LF_husband_wife_left_window(x: DataPoint, spouses: List[str]) -> int:\n",
    "    if len(set(spouses).intersection(set(x.person1_left_tokens))) > 0:\n",
    "        return 1\n",
    "    elif len(set(spouses).intersection(set(x.person2_left_tokens))) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "@labeling_function()\n",
    "def LF_same_last_name(x: DataPoint) -> int:\n",
    "    p1 = x.sentence.split(' ')[x.person1_word_range[0]:x.person1_word_range[1]+1]\n",
    "    p2 = x.sentence.split(' ')[x.person2_word_range[0]:x.person2_word_range[1]+1]\n",
    "    p1n = p1[-1] if len(p1) > 0 else None\n",
    "    p2n = p2[-1] if len(p2) > 0 else None\n",
    "    \n",
    "    if p1n and p2n and p1n == p2n:\n",
    "        if ' '.join(p1) != ' '.join(p2):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "@labeling_function()\n",
    "def LF_and_married(x: DataPoint) -> int:\n",
    "    return 1 if 'and' in x.between_tokens and 'married' in x.person2_right_tokens else 0    \n",
    "\n",
    "\n",
    "family = ['father', 'mother', 'sister', 'brother', 'son', 'daughter',\n",
    "              'grandfather', 'grandmother', 'uncle', 'aunt', 'cousin']\n",
    "family = family+[f + '-in-law' for f in family]\n",
    "\n",
    "@labeling_function(resources=dict(family=family))\n",
    "def LF_familial_relationship(x: DataPoint, family: List[str]) -> int:\n",
    "    return 1 if len(set(family).intersection(set(x.between_tokens))) > 0 else 0  \n",
    "\n",
    "\n",
    "@labeling_function(resources=dict(family=family))\n",
    "def LF_family_left_window(x: DataPoint, family: List[str]) -> int:\n",
    "    if len(set(family).intersection(set(x.person1_left_tokens))) > 0:\n",
    "        return -1\n",
    "    elif len(set(family).intersection(set(x.person2_left_tokens))) > 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "other = {'boyfriend', 'girlfriend' 'boss', 'employee', 'secretary', 'co-worker'}\n",
    "@labeling_function(resources=dict(other=other))\n",
    "def LF_other_relationship(x: DataPoint, other: List[str]) -> int:\n",
    "    for word in other:\n",
    "        return -1 if word in x.text_between.split(' ') else 0\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/2811 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█▍        | 416/2811 [00:00<00:00, 4152.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|███       | 858/2811 [00:00<00:00, 4227.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|████▌     | 1288/2811 [00:00<00:00, 4248.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 1697/2811 [00:00<00:00, 4199.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|███████▌  | 2129/2811 [00:00<00:00, 4234.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|█████████▏| 2569/2811 [00:00<00:00, 4280.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 2811/2811 [00:00<00:00, 4263.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "applier = PandasLFApplier([LF_husband_wife,\n",
    "                           LF_husband_wife_left_window,\n",
    "                           LF_same_last_name,\n",
    "                           LF_and_married, \n",
    "                           LF_familial_relationship,\n",
    "                           LF_family_left_window,\n",
    "                           LF_other_relationship])\n",
    "L = applier.apply(dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viewing Error Buckets\n",
    "If we have gold labeled data, we can evaluate formal metrics. It's useful to view specific errors for a given LF input in the `SentenceNgramViewer`.\n",
    "\n",
    "Below, we'll compute our empirical scores using human-labeled development set data and then look at any false positive matches by our `LF_marriage` LF. We can see below from our scores that this LF isn't very accurate -- only 36% precision!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LF_husband_wife coverage:  0.09178228388473852\n",
      "LF_husband_wife F1 score:  0.4196428571428571\n",
      "\n",
      "LF_and_married coverage:  0.0\n",
      "LF_and_married F1 score:  0\n"
     ]
    }
   ],
   "source": [
    "#TODO: pretty printer for LF stats\n",
    "\n",
    "from snorkel.model.metrics import coverage_score, f1_score\n",
    "\n",
    "print(\"LF_husband_wife coverage: \", coverage_score(dev_labels,L[:,0]))\n",
    "print(\"LF_husband_wife F1 score: \", f1_score(dev_labels,L[:,0]))\n",
    "print('')\n",
    "print(\"LF_and_married coverage: \", coverage_score(dev_labels,L[:,1]))\n",
    "print(\"LF_and_married F1 score: \", f1_score(dev_labels,L[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Distant Supervision Labeling Functions\n",
    "\n",
    "In addition to using factories that encode pattern matching heuristics, we can also write labeling functions that _distantly supervise_ examples. Here, we'll load in a list of known spouse pairs and check to see if the candidate pair matches one of these.\n",
    "\n",
    "**DBpedia**\n",
    "http://wiki.dbpedia.org/\n",
    "Out database of known spouses comes from DBpedia, which is a community-driven resource similar to Wikipedia but for curating structured data. We'll use a preprocessed snapshot as our knowledge base for all labeling function development.\n",
    "\n",
    "We can look at some of the example entries from DBPedia and use them in a simple distant supervision labeling function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Lady Anne Somerset', 'Thomas Percy'),\n",
       " ('Lau Lauritzen Jr.', 'Lisbeth Movin'),\n",
       " ('John Alexander', 'Robinson Thwaites'),\n",
       " ('Callie Khouri', 'T-Bone Burnett'),\n",
       " ('Anna Maria of Hesse-Kassel', 'Louis II Count of Nassau-Weilburg')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle \n",
    "\n",
    "with open('dbpedia.pkl', 'rb') as f:\n",
    "     known_spouses = pickle.load(f)\n",
    "        \n",
    "list(known_spouses)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(resources=dict(known_spouses=known_spouses))\n",
    "def LF_distant_supervision(x: DataPoint, known_spouses: List[str]) -> int:\n",
    "    p1 = x.sentence.split(' ')[x.person1_word_range[0]:x.person1_word_range[1]+1]\n",
    "    p2 = x.sentence.split(' ')[x.person2_word_range[0]:x.person2_word_range[1]+1]\n",
    "    p1, p2 = ' '.join(p1), ' '.join(p2)\n",
    "\n",
    "    return 1 if (p1, p2) in known_spouses or (p2, p1) in known_spouses else 0\n",
    "\n",
    "\n",
    "# Helper function to get last name\n",
    "def last_name(s):\n",
    "    name_parts = s.split(' ')\n",
    "    return name_parts[-1] if len(name_parts) > 1 else None \n",
    "\n",
    "# Last name pairs for known spouses\n",
    "last_names = set([(last_name(x), last_name(y)) for x, y in known_spouses if last_name(x) and last_name(y)])\n",
    "\n",
    "@labeling_function(resources=dict(last_names=last_names))\n",
    "def LF_distant_supervision_last_names(x: DataPoint, last_names: List[str]) -> int:\n",
    "    p1 = x.sentence.split(' ')[x.person1_word_range[0]:x.person1_word_range[1]+1]\n",
    "    p2 = x.sentence.split(' ')[x.person2_word_range[0]:x.person2_word_range[1]+1]\n",
    "    p1n = p1[-1] if len(p1) > 0 else None\n",
    "    p2n = p2[-1] if len(p2) > 0 else None\n",
    "    \n",
    "    return 1 if (p1 != p2) and ((p1n, p2n) in last_names or (p2n, p1n) in last_names) else 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/2811 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█▍        | 387/2811 [00:00<00:00, 3859.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██▊       | 795/2811 [00:00<00:00, 3920.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|████▎     | 1202/2811 [00:00<00:00, 3962.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████▋    | 1610/2811 [00:00<00:00, 3996.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████▏  | 2010/2811 [00:00<00:00, 3996.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████▌ | 2410/2811 [00:00<00:00, 3994.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|█████████▉| 2806/2811 [00:00<00:00, 3982.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 2811/2811 [00:00<00:00, 3984.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "applier = PandasLFApplier([LF_husband_wife,\n",
    "                           LF_husband_wife_left_window,\n",
    "                           LF_same_last_name,\n",
    "                           LF_and_married, \n",
    "                           LF_familial_relationship,\n",
    "                           LF_family_left_window,\n",
    "                           LF_other_relationship,\n",
    "                           LF_distant_supervision,\n",
    "                           LF_distant_supervision_last_names])\n",
    "L = applier.apply(dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Writing Custom Labeling Functions\n",
    "\n",
    "The strength of LFs is that you can write any arbitrary function and use it to supervise a classification task. This approach can combine many of the same strategies discussed above or encode other information. \n",
    "\n",
    "For example, we observe that when mentions of person names occur far apart in a sentence, this is a good indicator that the candidate's label is False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/2811 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|██████▊   | 1902/2811 [00:00<00:00, 19012.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 2811/2811 [00:00<00:00, 17261.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "@labeling_function()\n",
    "def LF_new(x: DataPoint) -> int:\n",
    "    return 0\n",
    "\n",
    "applier = PandasLFApplier([LF_husband_wife, LF_and_married,LF_new])\n",
    "L = applier.apply(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('dev_L.npy', L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO: make lf_stats/scorer function to print nice statistics__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Label Matrix Empirical Accuracies\n",
    "\n",
    "If we have a small set of human-labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>Empirical Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_TERMS_marriage_[between|words]_TRUE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.063323</td>\n",
       "      <td>0.063323</td>\n",
       "      <td>0.011740</td>\n",
       "      <td>61</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.358824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_TERMS_other_relationship_[left|words|window=1]_FALSE</th>\n",
       "      <td>1</td>\n",
       "      <td>0.003913</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_REGEX_exes_[between|words]_FALSE</th>\n",
       "      <td>2</td>\n",
       "      <td>0.004269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_DIST_SUPERVISION_dbpedia_TRUE</th>\n",
       "      <td>3</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_too_far_apart</th>\n",
       "      <td>4</td>\n",
       "      <td>0.068659</td>\n",
       "      <td>0.011028</td>\n",
       "      <td>0.011028</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>177</td>\n",
       "      <td>0.951613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_marriage_and_too_far_apart</th>\n",
       "      <td>5</td>\n",
       "      <td>0.052295</td>\n",
       "      <td>0.052295</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>58</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.414286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    j  Coverage  Overlaps  \\\n",
       "LF_TERMS_marriage_[between|words]_TRUE              0  0.063323  0.063323   \n",
       "LF_TERMS_other_relationship_[left|words|window=...  1  0.003913  0.001067   \n",
       "LF_REGEX_exes_[between|words]_FALSE                 2  0.004269  0.000000   \n",
       "LF_DIST_SUPERVISION_dbpedia_TRUE                    3  0.001067  0.000356   \n",
       "LF_too_far_apart                                    4  0.068659  0.011028   \n",
       "LF_marriage_and_too_far_apart                       5  0.052295  0.052295   \n",
       "\n",
       "                                                    Conflicts  TP   FP  FN  \\\n",
       "LF_TERMS_marriage_[between|words]_TRUE               0.011740  61  109   0   \n",
       "LF_TERMS_other_relationship_[left|words|window=...   0.001067   0    0   0   \n",
       "LF_REGEX_exes_[between|words]_FALSE                  0.000000   0    0   5   \n",
       "LF_DIST_SUPERVISION_dbpedia_TRUE                     0.000000   2    1   0   \n",
       "LF_too_far_apart                                     0.011028   0    0   9   \n",
       "LF_marriage_and_too_far_apart                        0.000711  58   82   0   \n",
       "\n",
       "                                                     TN  Empirical Acc.  \n",
       "LF_TERMS_marriage_[between|words]_TRUE                0        0.358824  \n",
       "LF_TERMS_other_relationship_[left|words|window=...   11        1.000000  \n",
       "LF_REGEX_exes_[between|words]_FALSE                   7        0.583333  \n",
       "LF_DIST_SUPERVISION_dbpedia_TRUE                      0        0.666667  \n",
       "LF_too_far_apart                                    177        0.951613  \n",
       "LF_marriage_and_too_far_apart                         0        0.414286  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_dev.lf_stats(session, labels=L_gold_dev.toarray().ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Iterating on Labeling Function Design\n",
    "\n",
    "When writing labeling functions, you will want to iterate on the process outlined above several times. You should focus on tuning individual LFs, based on emprical accuracy metrics, and adding new LFs to improve coverage. "
   ]
  }
 ],
 "metadata": {
  "anaconda-butt": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
