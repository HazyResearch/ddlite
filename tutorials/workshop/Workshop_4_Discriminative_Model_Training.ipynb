{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"imgs/logo.jpg\" width=\"50px\" style=\"margin-right:10px\">\n",
    "# Snorkel Workshop: Extracting Spouse Relations <br> from the News\n",
    "## Part 4: Training our End Extraction Model\n",
    "\n",
    "In this final section of the tutorial, we'll use the noisy training labels we generated in the last tutorial part to train our end extraction model.\n",
    "\n",
    "For this tutorial, we will be training a fairly effective deep learning model. More generally, however, Snorkel plugs in with many ML libraries including [TensorFlow](https://www.tensorflow.org/), making it easy to use almost any state-of-the-art model as the end extractor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload \n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Connect to the database backend and initalize a Snorkel session\n",
    "from lib.init import *\n",
    "from snorkel.annotations import load_marginals\n",
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Spouse = candidate_subclass('Spouse', ['person1', 'person2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Loading Candidates and Gold Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "train_cands = session.query(Spouse).filter(Spouse.split == 0).order_by(Spouse.id).all()\n",
    "dev_cands   = session.query(Spouse).filter(Spouse.split == 1).order_by(Spouse.id).all()\n",
    "test_cands  = session.query(Spouse).filter(Spouse.split == 2).order_by(Spouse.id).all()\n",
    "\n",
    "L_gold_train = load_gold_labels(session, annotator_name='gold', split=0, zero_one=True)\n",
    "L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1, load_as_array=True, zero_one=True)\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2, zero_one=True)\n",
    "\n",
    "#train_marginals = load_marginals(session, split=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Training a _Long Short-term Memory_ (LSTM) Neural Network\n",
    "\n",
    "[LSTMs](https://en.wikipedia.org/wiki/Long_short-term_memory) can acheive state-of-the-art performance on many text classification tasks. We'll train a simple LSTM model below. \n",
    "\n",
    "In deep learning, hyperparameter tuning is very important and computationally expensive step in training models. For purposes of this tutorial, we've pre-selected some settings so that you can train a model in under 10 minutes. Advanced users can look at our [Grid Search Tutorial](https://github.com/HazyResearch/snorkel/blob/master/tutorials/advanced/Hyperparameter_Search.ipynb) for more details on choosing these parameters. \n",
    "\n",
    "| Parameter           | Definition                                            |\n",
    "|---------------------|--------------------------------------------------------------------------------------------------------|\n",
    "| n_epochs            | A single pass through all the data in your training set                                                |\n",
    "| dim                 | Vector embedding (i.e., learned representation) dimension                                              |\n",
    "| lr,                 | The learning rate by which we update model weights after,computing the gradient                        |\n",
    "| dropout             | A neural network regularization techique [0.0 - 1.0]                                                   |\n",
    "| print_freq          | Print updates every k epochs                                                                           |\n",
    "| batch_size          | Estimate the gradient using k samples. Larger batch sizes run faster, but may perform worse            |\n",
    "| max_sentence_length | The max length of an input sequence. Setting this too large, can slow your training down substantially |\n",
    "                \n",
    "### Please Note !!!\n",
    "With the provided hyperparameters below, your model should train in about 9.5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM] Training model\n",
      "[LSTM] n_train=3115  #epochs=10  batch size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/snorkel/lib/python3.6/site-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM] Epoch 1 (12.32s)\tAverage loss=0.693709\tDev F1=12.37\n",
      "[LSTM] Epoch 2 (29.49s)\tAverage loss=0.693280\tDev F1=12.06\n",
      "[LSTM] Epoch 3 (45.57s)\tAverage loss=0.693159\tDev F1=11.80\n",
      "[LSTM] Epoch 4 (61.72s)\tAverage loss=0.693085\tDev F1=13.12\n",
      "[LSTM] Epoch 5 (78.21s)\tAverage loss=0.693019\tDev F1=12.70\n",
      "[LSTM] Epoch 6 (95.07s)\tAverage loss=0.692990\tDev F1=12.59\n",
      "[LSTM] Epoch 7 (112.05s)\tAverage loss=0.692936\tDev F1=12.41\n",
      "[LSTM] Epoch 8 (129.04s)\tAverage loss=0.692899\tDev F1=12.63\n",
      "[LSTM] Epoch 9 (144.90s)\tAverage loss=0.692852\tDev F1=12.53\n",
      "[LSTM] Model saved as <LSTM>\n",
      "[LSTM] Epoch 10 (162.11s)\tAverage loss=0.692813\tDev F1=12.80\n",
      "[LSTM] Model saved as <LSTM>\n",
      "[LSTM] Training done (166.52s)\n",
      "[LSTM] Loaded model <LSTM>\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning.pytorch.rnn import LSTM\n",
    "\n",
    "train_kwargs = {\n",
    "    'lr':         0.001,\n",
    "    'dim':        100,\n",
    "    'n_epochs':   10,\n",
    "    'dropout':    0.25,\n",
    "    'print_freq': 1,\n",
    "    'batch_size': 128,\n",
    "    'max_sentence_length': 100\n",
    "}\n",
    "\n",
    "lstm = LSTM(n_threads=1)\n",
    "lstm.train(train_cands, train_marginals, X_dev=dev_cands, Y_dev=L_gold_dev, **train_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we get the precision, recall, and F1 score from the discriminative model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.088, Recall: 0.661, F1 Score: 0.156\n"
     ]
    }
   ],
   "source": [
    "p, r, f1 = lstm.score(test_cands, L_gold_test)\n",
    "print(\"Prec: {0:.3f}, Recall: {1:.3f}, F1 Score: {2:.3f}\".format(p, r, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the candidates returned in sets (true positives, false positives, true negatives, false negatives) as well as a more detailed score report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.661\n",
      "Neg. class accuracy: 0.401\n",
      "Precision            0.0882\n",
      "Recall               0.661\n",
      "F1                   0.156\n",
      "----------------------------------------\n",
      "TP: 144 | FP: 1488 | TN: 995 | FN: 74\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = lstm.error_analysis(session, test_cands, L_gold_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's save our model for later use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM] Model saved as <spouse.lstm>\n"
     ]
    }
   ],
   "source": [
    "lstm.save(\"spouse.lstm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table names in the dictionary: dict_keys(['feature_key', 'candidate', 'label_key', 'gold_label_key', 'context', 'prediction_key', 'stable_label', 'gold_label', 'marginal', 'label', 'prediction', 'document', 'feature', 'sentence', 'span', 'spouse'])\n"
     ]
    }
   ],
   "source": [
    "def to_csv():\n",
    "    db = sqlite3.connect('snorkel.db')\n",
    "    cursor = db.cursor()\n",
    "    dfs = {}\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    for table_name in tables:\n",
    "        table_name = table_name[0]\n",
    "        table = pd.read_sql_query(\"SELECT * from %s\" % table_name, db)\n",
    "        table.to_csv(table_name + '.csv', index_label='index')\n",
    "        dfs[table_name] = table\n",
    "    cursor.close()\n",
    "    db.close()\n",
    "    return dfs\n",
    "\n",
    "dfs = to_csv()\n",
    "print(\"Table names in the dictionary:\", dfs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(dfs, open( \"list_of_tables.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  67820\n",
       "document_id         67820\n",
       "position            67820\n",
       "text                67820\n",
       "words               67820\n",
       "char_offsets        67820\n",
       "abs_char_offsets    67820\n",
       "lemmas              67820\n",
       "pos_tags            67820\n",
       "ner_tags            67820\n",
       "dep_parents         67820\n",
       "dep_labels          67820\n",
       "entity_cids         67820\n",
       "entity_types        67820\n",
       "dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['sentence'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id       27766\n",
       "type     27766\n",
       "split    27766\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['candidate'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             70412\n",
       "sentence_id    28836\n",
       "char_start        69\n",
       "char_end          73\n",
       "meta            None\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['span'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28836"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['span'].loc[0]['sentence_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26244    While many women saw the less-than-perfect ima...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['sentence'][dfs['sentence']['id'] == 28836]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26244    While many women saw the less-than-perfect ima...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
